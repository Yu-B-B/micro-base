解决的问题：主从模式中数据集中存储风险，分摊单个redis压力

结构：（一主多从）x N

数据基本分摊存储方式：顺序存储，但存在资源浪费，集中存储风险

提供的分区方案：基于哈希算法分区，分为“节点取余、一致性哈希分区、虚拟哈希分区”

节点取余：通过key计算hashcode，得到存储位置。但是节点变动会出现大量key映射改变。用于数量固定，不做分区

一致性哈希分区：得到hashcode，将key存入该位置，再由顺时针第一个节点管理。做扩容时节点分布不均匀，产生数据负载倾斜

虚拟哈希分区：将节点再映射大量虚拟节点分散在环上，得到hashcode，顺时针找第一个节点管理，分摊合理，但实现复杂。

数据分区总数为16384个节点，分散在0-16383个槽位中。

通过均匀分布将槽位分给各节点，个节点占区域内容。

这里的节点都是只主节点。

主节点之间通过Gossip协议，P2P方式做通信

添加新节点时，使用meet方式将信息发送给集群中节点。

通过ping命令，每秒发送信息到随机数量的节点中，找最早做过通信的节点。

找到的节点通过pong反馈此次通信时间与状态，若此次超时，将记录状态到维护的列表中

做通信时，访问的节点失效，将通信状态标记为pfail并存在本地，超过半数，认定为客观下线。

下线后，做节点选举：
1、判断：判断断开联机主节点关联的从节点是否拥有分槽，判断主节点断开时间是否小于cluster_node_timeout * 因子
2、选举延迟：判断从节点中那个节点同步率高就选那个
3、提升：将满足条件的从节点提升为主节点
4、投票：提升为主节点还未添加到集群中办事，还需要由其他主节点判断做选举
5、满足上述条件，该节点开始办事